{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOkySwdfWUhHj+b0QqYMlAP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"cby_1Zo8AF51"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","\n","#gohome\n","\n","idx2char = ['g', 'o', 'h', 'm', 'e']\n","\n","x_data = [[0, 1, 2, 1, 3]] #gohom\n","\n","x_one_hot = [[[1, 0, 0, 0],\n","              [0, 1, 0, 0],\n","              [0, 0, 1, 0],\n","              [0, 1, 0, 0],\n","              [0, 0, 0, 1]]]\n","\n","t_data = [[1, 2, 1, 3, 4]] #ohome\n","\n","# #foxfax\n","\n","# idx2char = ['f', 'o', 'x', 'a']\n","\n","# x_data = [[0, 1, 2, 0, 3]] #foxfa\n","\n","# x_one_hot = [[[1, 0, 0, 0],\n","#               [0, 1, 0, 0],\n","#               [0, 0, 1, 0],\n","#               [1, 0, 0, 0],\n","#               [0, 0, 0, 1]]]\n","\n","# t_data = [[1, 2, 0, 3, 2]] #oxfax\n","\n","# # hihello\n","\n","# idx2char = ['h', 'i', 'e', 'l', 'o']\n","\n","# x_data = [[0, 1, 0, 2, 3, 3]] #hihell\n","\n","# x_one_hot = [[[1, 0, 0, 0, 0],\n","#               [0, 1, 0, 0, 0],\n","#               [1, 0, 0, 0, 0],\n","#               [0, 0, 1, 0, 0],\n","#               [0, 0, 0, 1, 0],\n","#               [0, 0, 0, 1, 0]]]\n","\n","# t_data = [[1, 0, 2, 3, 3, 4]] #ihello\n","\n","# num_classes = 6\n","# input_dim = 4\n","# hidden_size = 6\n","# batch_size = 1\n","# squence_length = 6\n","# learning_rate = 0.1\n","\n","num_classes = 5\n","input_dim = 4\n","hidden_size = 5\n","batch_size = 1\n","sequence_length = 5\n","learning_rate = 0.1\n","\n","X = tf.placeholder(tf.float32, [None, sequence_length, input_dim])\n","T = tf.placeholder(tf.float32, [None, sequence_length])"]},{"cell_type":"code","source":["cell = tf.contrib.rnn.BasicRNNCell(num_units=hidden_size)\n","\n","initial_state = cell.zero_state(batch_size, tf.float32)\n","\n","outputs, _states = tf.nn.dynamic_rnn(cell, X, initial_state=initial_state, dtype=tf.float32)\n","\n","weights = tf.ones([batch_size, sequence_length])\n","\n","seq_loss = tf.contrib.seq2seq.sequence_loss(logits=outputs, targets=T, weights=weights)\n","\n","loss = tf.reduce_mean(seq_loss)\n","\n","train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"],"metadata":{"id":"ruVSuvrmARGQ","executionInfo":{"status":"ok","timestamp":1706713029130,"user_tz":-540,"elapsed":339,"user":{"displayName":"김영훈","userId":"18232318797082622169"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["y = prediction = tf.argmax(outputs, axis=2)\n","\n","with tf.Session() as sess :\n","\n","  sess.run(tf.global_variable_initializer())\n","\n","  for step in range(2001) :\n","\n","    loss_val, _ = sess.run([loss, train], feed_dict={X: x_one_hot, T: t_data})\n","    result = sess.run(y, feed_dict{X : x_one_hot})\n","\n","    if step % 400 == 0 :\n","      print(\"step = \", step, \", loss = \", loss_val, \", prediction = \", result, \", target= \", t_data)\n","\n","      result_str = [idx2char[c] for c in np.squeeze(result)]\n","\n","      print(\"\\nPrediction = \", ''.join(result_str))"],"metadata":{"id":"54rOQrPjARHU","executionInfo":{"status":"ok","timestamp":1706713023532,"user_tz":-540,"elapsed":304,"user":{"displayName":"김영훈","userId":"18232318797082622169"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"37VH4yH8ARdO"},"execution_count":null,"outputs":[]}]}